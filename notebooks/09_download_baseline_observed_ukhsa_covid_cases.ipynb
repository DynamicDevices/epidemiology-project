{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline (observed) dataset: COVID-19 cases vs time (England, UKHSA)\n",
        "\n",
        "## What this notebook is doing (in plain English)\n",
        "\n",
        "We want a dataset that is basically **“time vs infected”**.\n",
        "\n",
        "In real life, we usually *cannot* measure “how many people are infected right now” perfectly. Instead, we use a **proxy** (a measurable quantity that is related to infections). In this notebook, we use:\n",
        "\n",
        "- **confirmed COVID-19 cases by day** (England)\n",
        "\n",
        "This is a good first *observed* time series to work with because it’s a simple “counts over time” dataset.\n",
        "\n",
        "## Why this is called “baseline (observed)”\n",
        "\n",
        "- **Observed**: it comes from a real surveillance source (UKHSA dashboard), not a simulation.\n",
        "- **Baseline**: it’s our starting point before we build “what-if” *intervention scenarios* using a model.\n",
        "\n",
        "Important: this observed baseline is **not** “no interventions happened in the real world”. It is simply the cleanest pre-existing dataset that matches “time vs infected (proxy)”.\n",
        "\n",
        "## What you will produce\n",
        "\n",
        "- A CSV file saved to:\n",
        "  - `data/processed/observed/ukhsa_covid19_cases_by_day_england.csv`\n",
        "- A plot of **date vs cases** (and optionally a smoothed version)\n",
        "\n",
        "## How to read the main columns\n",
        "\n",
        "- **date**: the day of observation\n",
        "- **cases**: number of confirmed cases reported for that day (proxy for “infected”)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620052ee",
      "metadata": {},
      "source": [
        "## Alternative ways to call the UKHSA API (without our custom helper)\n",
        "\n",
        "In this notebook we use a small helper from `epidemiology_project.ukhsa` so that the *data science part* stays simple.\n",
        "\n",
        "But there **are** other approaches, especially because UKHSA publishes an **OpenAPI/Swagger** schema:\n",
        "\n",
        "- Swagger UI: `https://api.ukhsa-dashboard.data.gov.uk/api/swagger`\n",
        "- OpenAPI schema JSON: `https://api.ukhsa-dashboard.data.gov.uk/api/schema`\n",
        "\n",
        "### Option A — Use the UKHSA API directly with `requests` (simplest “no helper”)\n",
        "\n",
        "This is the simplest *library-based* approach because `requests` is the standard HTTP library.\n",
        "\n",
        "You:\n",
        "- build the metric URL\n",
        "- call `requests.get(...)`\n",
        "- follow the `next` links to get all pages\n",
        "\n",
        "(We do exactly this logic inside the helper, so you don’t have to re-write it in every notebook.)\n",
        "\n",
        "### Option B — Use a runtime OpenAPI client (Swagger client)\n",
        "\n",
        "There are libraries that can load the OpenAPI schema and let you call endpoints more “object-like”.\n",
        "\n",
        "Example candidates:\n",
        "- `bravado` (Swagger/OpenAPI runtime client)\n",
        "\n",
        "This can feel convenient, but you still need to understand:\n",
        "- which endpoint you want\n",
        "- pagination (`next` links)\n",
        "\n",
        "### Option C — Generate a Python client from OpenAPI (most “SDK-like”)\n",
        "\n",
        "Tools like these can generate a typed client from the schema:\n",
        "- `openapi-python-client`\n",
        "- OpenAPI Generator\n",
        "\n",
        "Typical workflow:\n",
        "1. Download the schema (`/api/schema`)\n",
        "2. Generate client code\n",
        "3. Import the generated client in notebooks\n",
        "\n",
        "This can be great in bigger projects, but it adds setup/maintenance overhead for a first-year project.\n",
        "\n",
        "### What we recommend for this project\n",
        "\n",
        "- Start with the **simple helper** (`fetch_timeseries` / `fetch_metric`) so you can focus on the maths and plots.\n",
        "- If you later want to explore the OpenAPI approach, see `docs/GETTING_DATA_FROM_THE_WEB.md`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.ukhsa-dashboard.data.gov.uk/v2/themes/infectious_disease/sub_themes/respiratory/topics/COVID-19/geography_types/Nation/geographies/England/metrics/COVID-19_cases_casesByDay\"\n",
        "\n",
        "rows = []\n",
        "while url:\n",
        "    data = requests.get(url).json()\n",
        "    rows += data[\"results\"]\n",
        "    url = data[\"next\"]\n",
        "\n",
        "rows[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from epidemiology_project.paths import processed_data_dir, figures_dir\n",
        "from epidemiology_project.ukhsa import UksHaMetricQuery, fetch_metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download from UKHSA API\n",
        "\n",
        "### What is the UKHSA API?\n",
        "\n",
        "UKHSA (UK Health Security Agency) publishes a public dashboard. Behind the dashboard is an **API** (Application Programming Interface): a set of URLs that return data in a structured format (JSON).\n",
        "\n",
        "We use a small helper (`fetch_metric`) that downloads the data and handles pagination (when the API splits results into multiple pages).\n",
        "\n",
        "### What is this “query” object?\n",
        "\n",
        "`UksHaMetricQuery(...)` just stores the choices that identify *which* dataset we want:\n",
        "\n",
        "- **theme/sub_theme/topic**: what area of public health (here: infectious disease → respiratory → COVID-19)\n",
        "- **geography_type/geography**: what area (here: Nation → England)\n",
        "- **metric**: what measure (here: confirmed cases by day)\n",
        "\n",
        "If you change these values, you get a different dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q = UksHaMetricQuery(\n",
        "    theme='infectious_disease',\n",
        "    sub_theme='respiratory',\n",
        "    topic='COVID-19',\n",
        "    geography_type='Nation',\n",
        "    geography='England',\n",
        "    metric='COVID-19_cases_casesByDay',\n",
        ")\n",
        "\n",
        "df_raw = fetch_metric(q)\n",
        "df_raw[['date','metric_value']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keep only the time series we need\n",
        "\n",
        "The API returns a table with many columns (theme, geography codes, age bands, etc.). For a first “infected vs time” plot we only need:\n",
        "\n",
        "- the **date** column (time)\n",
        "- the **metric_value** column (the number for that day)\n",
        "\n",
        "We also:\n",
        "\n",
        "- drop missing values (`dropna`) so the plot won’t break\n",
        "- sort by date so the line goes left-to-right correctly\n",
        "- rename `metric_value` to `cases` so the meaning is obvious\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df_raw[['date', 'metric_value']].dropna().sort_values('date')\n",
        "df = df.rename(columns={'metric_value': 'cases'})\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save to `data/processed/` (observed baseline)\n",
        "\n",
        "### Why do we save a CSV?\n",
        "\n",
        "Notebooks are great for exploring, but it’s good practice to also save the *dataset you actually used* as a file. That way:\n",
        "\n",
        "- everyone in the group can load the same data later\n",
        "- you can rerun plots without re-downloading every time\n",
        "- you have a clear “checkpoint” for reproducibility\n",
        "\n",
        "### Why `data/processed/observed/`?\n",
        "\n",
        "- `data/raw/` is for original downloads you never change.\n",
        "- `data/processed/` is for cleaned, ready-to-plot datasets.\n",
        "- `observed/` means this dataset comes from **real surveillance**, not a simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = processed_data_dir() / 'observed'\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_path = out_dir / 'ukhsa_covid19_cases_by_day_england.csv'\n",
        "df.to_csv(out_path, index=False)\n",
        "out_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot: time vs infected (proxy)\n",
        "\n",
        "This is the key picture: **a time series**.\n",
        "\n",
        "- **x-axis**: time (date)\n",
        "- **y-axis**: daily confirmed cases (our proxy for “infected”)\n",
        "\n",
        "### What should you look for?\n",
        "\n",
        "- **Waves/peaks**: times when cases rise and fall\n",
        "- **Skewness**: a fast rise and slow fall is common in epidemics\n",
        "- **Noise**: daily data has reporting effects (weekends, backlogs)\n",
        "\n",
        "This is why we also show a smoothed curve next.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(11,5))\n",
        "ax.plot(df['date'], df['cases'], linewidth=1)\n",
        "ax.set_title('England: confirmed COVID-19 cases by day (UKHSA)')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Cases')\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig.tight_layout()\n",
        "\n",
        "fig_path = figures_dir(final=True) / 'ukhsa_observed_baseline_covid_cases_by_day_england.png'\n",
        "fig.savefig(fig_path, dpi=200)\n",
        "fig_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: smoother curve (7-day mean)\n",
        "\n",
        "Daily case counts are often “bumpy” because of reporting patterns.\n",
        "\n",
        "A simple way to reduce noise is a **rolling mean**. A 7-day rolling mean replaces each day’s value with the average of the last 7 days.\n",
        "\n",
        "Mathematically, if daily cases are \\(c_t\\), the 7-day rolling mean is:\n",
        "\n",
        "\\[\n",
        "\\bar{c}_t = \\frac{1}{7}\\sum_{k=0}^{6} c_{t-k}\n",
        "\\]\n",
        "\n",
        "This keeps the overall shape (waves) but makes it easier to compare peaks and trends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = df.set_index('date').copy()\n",
        "df2['cases_7d_mean'] = df2['cases'].rolling(7).mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11,5))\n",
        "ax.plot(df2.index, df2['cases_7d_mean'], linewidth=1.5)\n",
        "ax.set_title('England: confirmed COVID-19 cases (7-day mean)')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Cases (7-day mean)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig.tight_layout()\n",
        "\n",
        "fig_path = figures_dir(final=True) / 'ukhsa_observed_baseline_covid_cases_by_day_england_7dmean.png'\n",
        "fig.savefig(fig_path, dpi=200)\n",
        "fig_path\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
